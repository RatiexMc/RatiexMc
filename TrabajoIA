{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "LNo_3IBJ1iOB",
        "CIbEgOIw2ov5",
        "Vsi6q03E6mDT",
        "b9NLrNt79UqC",
        "fJmZb6aM_euD"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN0RuKcT5THkjts15KQujYS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RatiexMc/RatiexMc/blob/main/TrabajoIA\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "######Breast Cancer Wisconsin(Cáncer de Mama en el estado de Wisconsin)\n",
        "######-Descripción: Predecir si un tumor es maligno o beningno\n",
        "######-Características: 30\n",
        "######-Carga: Desde sklearn\n",
        "######Enlace: https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic\n"
      ],
      "metadata": {
        "id": "aLyjLKMt0pdq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "######1.Carga el Dataset"
      ],
      "metadata": {
        "id": "LNo_3IBJ1iOB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "# Cargar el archivo CSV\n",
        "df = pd.read_csv(\"db_cancerwiscoin.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "GLMrDcex1uOB",
        "outputId": "ac7dbd93-6fc8-4c91-899d-b1733f340db9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-437fb00f-4f04-4c70-ab24-e6e2d04cc318\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-437fb00f-4f04-4c70-ab24-e6e2d04cc318\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving db_cancerwiscoin.csv to db_cancerwiscoin (1).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "######2.Explorar y entender los datos"
      ],
      "metadata": {
        "id": "CIbEgOIw2ov5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 2: Explorar y entender los datos\n",
        "\n",
        "# 1. Ver las dimensiones del DataFrame (filas, columnas)\n",
        "print(f\"1)Dimensiones del dataset: {df.shape}\")\n",
        "  # Ver cantidad de n_filas y n_columnas)\n",
        "\n",
        "# 2. Ver nombres de columnas\n",
        "print(\"\\n2)Nombre de columnas:\")\n",
        "print(df.columns.tolist())\n",
        "  #Ver los nombres de las columnas\n",
        "\n",
        "# 3. Ver las primeras filas del dataset\n",
        "print(\"\\n3)Primeras 5 filas:\")\n",
        "print(df.head())\n",
        "  #Ver las primeras 5 filas del dataset\n",
        "\n",
        "# 4. Tipos de datos y valores no nulos por columna\n",
        "print(\"\\n4)Información general del DataFrame:\")\n",
        "print(df.info())\n",
        "  #Muestra el total de filas, el nombre de cada columna, el numero de valores no nulos por columnas\n",
        "  #(es decir cuantas datos válidos tienen cada una), el tipo de datos de cada columna\n",
        "  #Es importante para verificar valores faltantes e identificar si algo fue malcargada\n",
        "\n",
        "# 5. Estadísticas descriptivas para variables numéricas\n",
        "print(\"\\n5)Estadísticas descriptivas:\")\n",
        "print(df.describe())\n",
        "  #Muestra estadística básica de las columnas numéricas del dataframe:\n",
        "  #count: número de valores no nulos\n",
        "  #mean: promedio\n",
        "  #std: desviación estándar\n",
        "  #min: valor mínimo\n",
        "  #25%,50% (mediana),75% percentiles\n",
        "  #max: valor máximo\n",
        "  #Ayuda a detectar outliers o valores extremos, comprende la distribuicion y escala de cada variable\n",
        "  #y sirve para evalular si alguna columna tiene poca variabilidad(poca información útil)\n",
        "\n",
        "# 6. Revisar si existen valores nulos\n",
        "print(\"\\n6)¿Hay valores nulos por columna?\")\n",
        "print(df.isnull().sum())\n",
        "  #Verifica si existen valores nulos por columnas\n",
        "\n",
        "# 7. Revisar si hay valores duplicados\n",
        "print(\"\\n7)¿Hay filas duplicadas?\")\n",
        "print(df.duplicated().sum())\n",
        "  #Verifica si hay valores que son duplicadas\n",
        "\n",
        "# 8. Distribución de la variable objetivo (target)\n",
        "if 'diagnosis' in df.columns:\n",
        "    print(\"\\n8)Distribución de la variable objetivo ('diagnosis'):\")\n",
        "    print(df['diagnosis'].value_counts())\n",
        "else:\n",
        "    print(\"\\nAdvertencia: No se encontró una columna 'diagnosis' para analizar la variable objetivo.\")\n",
        "  #Cuenta cuántas veces aparece cada clase de la variable diagnosis(M: maligno, B: benigno)\n",
        "  #Es imporante para verificar si hay balance de clases\n",
        "  #345 benignos(B)\n",
        "  #212 malignos(M)\n",
        "  #Ya que si hay gran desbalance, puede afectar el rendimiento del modelo, ya que podría sesgarse\n",
        "  #hacia la clase mayoritaria\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4abrF7O2-Ux",
        "outputId": "49ebcb8e-d410-456a-dbb9-df293d76621d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1)Dimensiones del dataset: (569, 32)\n",
            "\n",
            "2)Nombre de columnas:\n",
            "['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean', 'concave_points_mean', 'symmetry_mean', 'fractal_dimension_mean', 'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se', 'compactness_se', 'concavity_se', 'concave_points_se', 'symmetry_se', 'fractal_dimension_se', 'radius_worst', 'texture_worst', 'perimeter_worst', 'area_worst', 'smoothness_worst', 'compactness_worst', 'concavity_worst', 'concave_points_worst', 'symmetry_worst', 'fractal_dimension_worst']\n",
            "\n",
            "3)Primeras 5 filas:\n",
            "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
            "0    842302         M        17.99         10.38          122.80     1001.0   \n",
            "1    842517         M        20.57         17.77          132.90     1326.0   \n",
            "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
            "3  84348301         M        11.42         20.38           77.58      386.1   \n",
            "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
            "\n",
            "   smoothness_mean  compactness_mean  concavity_mean  concave_points_mean  \\\n",
            "0          0.11840           0.27760          0.3001              0.14710   \n",
            "1          0.08474           0.07864          0.0869              0.07017   \n",
            "2          0.10960           0.15990          0.1974              0.12790   \n",
            "3          0.14250           0.28390          0.2414              0.10520   \n",
            "4          0.10030           0.13280          0.1980              0.10430   \n",
            "\n",
            "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
            "0  ...         25.38          17.33           184.60      2019.0   \n",
            "1  ...         24.99          23.41           158.80      1956.0   \n",
            "2  ...         23.57          25.53           152.50      1709.0   \n",
            "3  ...         14.91          26.50            98.87       567.7   \n",
            "4  ...         22.54          16.67           152.20      1575.0   \n",
            "\n",
            "   smoothness_worst  compactness_worst  concavity_worst  concave_points_worst  \\\n",
            "0            0.1622             0.6656           0.7119                0.2654   \n",
            "1            0.1238             0.1866           0.2416                0.1860   \n",
            "2            0.1444             0.4245           0.4504                0.2430   \n",
            "3            0.2098             0.8663           0.6869                0.2575   \n",
            "4            0.1374             0.2050           0.4000                0.1625   \n",
            "\n",
            "   symmetry_worst  fractal_dimension_worst  \n",
            "0          0.4601                  0.11890  \n",
            "1          0.2750                  0.08902  \n",
            "2          0.3613                  0.08758  \n",
            "3          0.6638                  0.17300  \n",
            "4          0.2364                  0.07678  \n",
            "\n",
            "[5 rows x 32 columns]\n",
            "\n",
            "4)Información general del DataFrame:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 32 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   id                       569 non-null    int64  \n",
            " 1   diagnosis                569 non-null    object \n",
            " 2   radius_mean              569 non-null    float64\n",
            " 3   texture_mean             569 non-null    float64\n",
            " 4   perimeter_mean           569 non-null    float64\n",
            " 5   area_mean                569 non-null    float64\n",
            " 6   smoothness_mean          569 non-null    float64\n",
            " 7   compactness_mean         569 non-null    float64\n",
            " 8   concavity_mean           569 non-null    float64\n",
            " 9   concave_points_mean      569 non-null    float64\n",
            " 10  symmetry_mean            569 non-null    float64\n",
            " 11  fractal_dimension_mean   569 non-null    float64\n",
            " 12  radius_se                569 non-null    float64\n",
            " 13  texture_se               569 non-null    float64\n",
            " 14  perimeter_se             569 non-null    float64\n",
            " 15  area_se                  569 non-null    float64\n",
            " 16  smoothness_se            569 non-null    float64\n",
            " 17  compactness_se           569 non-null    float64\n",
            " 18  concavity_se             569 non-null    float64\n",
            " 19  concave_points_se        569 non-null    float64\n",
            " 20  symmetry_se              569 non-null    float64\n",
            " 21  fractal_dimension_se     569 non-null    float64\n",
            " 22  radius_worst             569 non-null    float64\n",
            " 23  texture_worst            569 non-null    float64\n",
            " 24  perimeter_worst          569 non-null    float64\n",
            " 25  area_worst               569 non-null    float64\n",
            " 26  smoothness_worst         569 non-null    float64\n",
            " 27  compactness_worst        569 non-null    float64\n",
            " 28  concavity_worst          569 non-null    float64\n",
            " 29  concave_points_worst     569 non-null    float64\n",
            " 30  symmetry_worst           569 non-null    float64\n",
            " 31  fractal_dimension_worst  569 non-null    float64\n",
            "dtypes: float64(30), int64(1), object(1)\n",
            "memory usage: 142.4+ KB\n",
            "None\n",
            "\n",
            "5)Estadísticas descriptivas:\n",
            "                 id  radius_mean  texture_mean  perimeter_mean    area_mean  \\\n",
            "count  5.690000e+02   569.000000    569.000000      569.000000   569.000000   \n",
            "mean   3.037183e+07    14.127292     19.289649       91.969033   654.889104   \n",
            "std    1.250206e+08     3.524049      4.301036       24.298981   351.914129   \n",
            "min    8.670000e+03     6.981000      9.710000       43.790000   143.500000   \n",
            "25%    8.692180e+05    11.700000     16.170000       75.170000   420.300000   \n",
            "50%    9.060240e+05    13.370000     18.840000       86.240000   551.100000   \n",
            "75%    8.813129e+06    15.780000     21.800000      104.100000   782.700000   \n",
            "max    9.113205e+08    28.110000     39.280000      188.500000  2501.000000   \n",
            "\n",
            "       smoothness_mean  compactness_mean  concavity_mean  concave_points_mean  \\\n",
            "count       569.000000        569.000000      569.000000           569.000000   \n",
            "mean          0.096360          0.104341        0.088799             0.048919   \n",
            "std           0.014064          0.052813        0.079720             0.038803   \n",
            "min           0.052630          0.019380        0.000000             0.000000   \n",
            "25%           0.086370          0.064920        0.029560             0.020310   \n",
            "50%           0.095870          0.092630        0.061540             0.033500   \n",
            "75%           0.105300          0.130400        0.130700             0.074000   \n",
            "max           0.163400          0.345400        0.426800             0.201200   \n",
            "\n",
            "       symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
            "count     569.000000  ...    569.000000     569.000000       569.000000   \n",
            "mean        0.181162  ...     16.269190      25.677223       107.261213   \n",
            "std         0.027414  ...      4.833242       6.146258        33.602542   \n",
            "min         0.106000  ...      7.930000      12.020000        50.410000   \n",
            "25%         0.161900  ...     13.010000      21.080000        84.110000   \n",
            "50%         0.179200  ...     14.970000      25.410000        97.660000   \n",
            "75%         0.195700  ...     18.790000      29.720000       125.400000   \n",
            "max         0.304000  ...     36.040000      49.540000       251.200000   \n",
            "\n",
            "        area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
            "count   569.000000        569.000000         569.000000       569.000000   \n",
            "mean    880.583128          0.132369           0.254265         0.272188   \n",
            "std     569.356993          0.022832           0.157336         0.208624   \n",
            "min     185.200000          0.071170           0.027290         0.000000   \n",
            "25%     515.300000          0.116600           0.147200         0.114500   \n",
            "50%     686.500000          0.131300           0.211900         0.226700   \n",
            "75%    1084.000000          0.146000           0.339100         0.382900   \n",
            "max    4254.000000          0.222600           1.058000         1.252000   \n",
            "\n",
            "       concave_points_worst  symmetry_worst  fractal_dimension_worst  \n",
            "count            569.000000      569.000000               569.000000  \n",
            "mean               0.114606        0.290076                 0.083946  \n",
            "std                0.065732        0.061867                 0.018061  \n",
            "min                0.000000        0.156500                 0.055040  \n",
            "25%                0.064930        0.250400                 0.071460  \n",
            "50%                0.099930        0.282200                 0.080040  \n",
            "75%                0.161400        0.317900                 0.092080  \n",
            "max                0.291000        0.663800                 0.207500  \n",
            "\n",
            "[8 rows x 31 columns]\n",
            "\n",
            "6)¿Hay valores nulos por columna?\n",
            "id                         0\n",
            "diagnosis                  0\n",
            "radius_mean                0\n",
            "texture_mean               0\n",
            "perimeter_mean             0\n",
            "area_mean                  0\n",
            "smoothness_mean            0\n",
            "compactness_mean           0\n",
            "concavity_mean             0\n",
            "concave_points_mean        0\n",
            "symmetry_mean              0\n",
            "fractal_dimension_mean     0\n",
            "radius_se                  0\n",
            "texture_se                 0\n",
            "perimeter_se               0\n",
            "area_se                    0\n",
            "smoothness_se              0\n",
            "compactness_se             0\n",
            "concavity_se               0\n",
            "concave_points_se          0\n",
            "symmetry_se                0\n",
            "fractal_dimension_se       0\n",
            "radius_worst               0\n",
            "texture_worst              0\n",
            "perimeter_worst            0\n",
            "area_worst                 0\n",
            "smoothness_worst           0\n",
            "compactness_worst          0\n",
            "concavity_worst            0\n",
            "concave_points_worst       0\n",
            "symmetry_worst             0\n",
            "fractal_dimension_worst    0\n",
            "dtype: int64\n",
            "\n",
            "7)¿Hay filas duplicadas?\n",
            "0\n",
            "\n",
            "8)Distribución de la variable objetivo ('diagnosis'):\n",
            "diagnosis\n",
            "B    357\n",
            "M    212\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "######3.Limpiar los datos(Valores faltantes, tipos, duplicados)"
      ],
      "metadata": {
        "id": "Vsi6q03E6mDT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 3: Limpiar los datos\n",
        "# 1. Eliminar filas duplicadas si las hay\n",
        "n_duplicados = df.duplicated().sum()\n",
        "if n_duplicados > 0:\n",
        "    df = df.drop_duplicates()\n",
        "    print(f\"{n_duplicados} filas duplicadas eliminadas.\")\n",
        "else:\n",
        "    print(\"No se encontraron filas duplicadas.\")\n",
        "  #Identifica si existen filas duplicados y la eliminamos\n",
        "\n",
        "# 2. Manejar valores faltantes\n",
        "n_nulos = df.isnull().sum().sum()\n",
        "if n_nulos > 0:\n",
        "    print(f\"Hay {n_nulos} valores nulos en el dataset.\")\n",
        "    # Opción básica: eliminar filas con valores nulos\n",
        "    df = df.dropna()\n",
        "    print(\"Filas con valores nulos eliminadas.\")\n",
        "else:\n",
        "    print(\"No se encontraron valores nulos.\")\n",
        "  # Eliminar valores faltantes\n",
        "\n",
        "# 3. Verificar y corregir tipos de datos si es necesario\n",
        "# Ejemplo: convertir columna 'diagnosis' a categoría si es tipo object\n",
        "if df['diagnosis'].dtype == 'object':\n",
        "    df['diagnosis'] = df['diagnosis'].astype('category')\n",
        "    print(\"Columna 'diagnosis' convertida a tipo categoría.\")\n",
        "# Mostrar estado final\n",
        "print(f\"Dataset limpio. Tamaño actual: {df.shape}\")\n",
        "  #Convierte la columna diagnosis(objetivo) de tipo object(texto) a tipo category(categoría)\n",
        "  #Ya que es buena práctica convertir texto que representen categoíra en objetos optimizados para\n",
        "  #clasificarlos. Esto ayuda en análisis y codifícaciones posteriores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtiA2WC16w8y",
        "outputId": "0bbf910d-85b4-4291-e614-c0bc34249882"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No se encontraron filas duplicadas.\n",
            "No se encontraron valores nulos.\n",
            "Columna 'diagnosis' convertida a tipo categoría.\n",
            "Dataset limpio. Tamaño actual: (569, 32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "######4.Seleccionar las características(X) y la variable objetivo(Y)"
      ],
      "metadata": {
        "id": "gNiDAlCr9HYK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 4: Seleccionar características (X) y variable objetivo (y)\n",
        "\n",
        "# 1. Seleccionar la variable objetivo (por ejemplo: 'diagnosis')\n",
        "y = df['diagnosis']\n",
        "\n",
        "# 2. Seleccionar las características: todas las columnas excepto 'diagnosis'\n",
        "X = df.drop('diagnosis', axis=1)\n",
        "\n",
        "# 3. Confirmar las dimensiones\n",
        "print(f\"Características (X): {X.shape[1]} columnas\")\n",
        "print(f\"Variable objetivo (y): {y.name}\")\n",
        "print(f\"Total de muestras: {X.shape[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYkcgtyd9RM6",
        "outputId": "c413cf30-70d3-46b0-c86f-94c68660493a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Características (X): 31 columnas\n",
            "Variable objetivo (y): diagnosis\n",
            "Total de muestras: 569\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "######5.Codificar variables categóricas(si existen)"
      ],
      "metadata": {
        "id": "b9NLrNt79UqC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 5: Codificar variables categóricas (si existen)\n",
        " #Estos nos permite entrenar el modelo de clasificación finaria sin errores de tipo,\n",
        " #Transforma la categoría tipo string a número\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# 1. Codificar la variable objetivo (diagnosis: M = maligno, B = benigno)\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "\n",
        "# 2. Verificar la codificación: 0 y 1\n",
        "print(\"Valores únicos en y codificada:\", set(y_encoded))\n",
        "print(f\"'B' (benigno) = {le.transform(['B'])[0]}, 'M' (maligno) = {le.transform(['M'])[0]}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEGO7Ej79zpT",
        "outputId": "e03a80be-279c-484f-d212-4627ab975df6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valores únicos en y codificada: {np.int64(0), np.int64(1)}\n",
            "'B' (benigno) = 0, 'M' (maligno) = 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "######6.Dividir el dataset en entrenamiento y prueba(train/test)"
      ],
      "metadata": {
        "id": "_FmuV6-M-R8L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 6: Dividir el dataset en entrenamiento y prueba\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Dividir: 80% para entrenamiento, 20% para prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
        ")\n",
        "\n",
        "# Verificar las dimensiones\n",
        "print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
        "print(f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
        "\n",
        "  #Detalles:\n",
        "  #test_size=0.2: Reserva el 20% de los datos para evaluar el modelo y 80% para entrenar el modelo\n",
        "  #random_state=42: Asegura que los resultados sean reproducibles\n",
        "  #statify=y_encoded: Mantiene la misma proporción de clases en ambos conjuntos(estratificación)\n",
        "  #esto evita que la clase esté sobrerepresentada o ausente en uno de los subconjuntos\n",
        "  #Por ejemplo, si 30% de los datos son malignos, se asegura que ambos conjuntos (entrenamiento\n",
        "  #y prueba) tengan ese mismo 30%."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-loCB7fH-bVC",
        "outputId": "15d31232-dde4-419e-ab59-e334fbdb32ca"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: (455, 31), y_train: (455,)\n",
            "X_test: (114, 31), y_test: (114,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "######7.Normalizar o Escalar si es necesario(opcional)"
      ],
      "metadata": {
        "id": "fJmZb6aM_euD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Objetivo:\n",
        "#Ajustar la escala de los datos si el modelo lo requiere.\n",
        "#En el caso de Random Forest, NO es necesario escalar ni normalizar, ya que los árboles de decisión no son sensibles a la escala de las variables.\n",
        "#¿Por qué no se normaliza en Random Forest?\n",
        "#Modelos basados en árboles (como Random Forest, Decision Tree, Gradient Boosting) dividen los datos por umbrales, no por distancias.\n",
        "#Por eso, una variable en escala 0–1000 y otra en escala 0–1 tienen el mismo peso al decidir divisiones\n",
        "#¿Qué se hace entonces en este paso?\n",
        "#Simplemente documentamos que no se escalará, para dejar claro que el modelo no lo requiere.\n",
        "# Paso 7: Escalado de datos\n",
        "print(\"Random Forest no requiere normalización ni escalado de datos. Se continúa sin transformación.\")"
      ],
      "metadata": {
        "id": "pinTVp4E_61r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### 8.Instanciar el modelo RandomForest(Definir Hiperparámetros)"
      ],
      "metadata": {
        "id": "n0VxtenlAjib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# Instanciar el clasificador con hiperparámetros iniciales\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=None,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "# Confirmar la creación del modelo\n",
        "print(\"Modelo Random Forest instanciado con parámetros por defecto.\")\n",
        "  #n_estimators=100 -> Número de árboles que compondrán el bosque, Más arboles = mejor precisón, pero más tiempo de cómputo\n",
        "  #max_depth=None -> Los árboles crecerán hasta que cada hoja sea pura o tenga muy poco datos. Puedes limitarlo para evitar sobreajuste\n",
        "  #random_state=42 -> Asegura los resultados reproducibles\n",
        "  #n_jobs=-1 -> Usa todos los núcleos del procesador para entrenar más  rápido\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbioqFJ5AwQz",
        "outputId": "9a37a47a-6c82-4a60-da32-5c73d47a546b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo Random Forest instanciado con parámetros por defecto.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "######9.Entrenar el modelo(fit)"
      ],
      "metadata": {
        "id": "y6livan_BkV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento del modelo\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Confirmación\n",
        "print(\"Entrenamiento completado. El modelo ya está ajustado a los datos.\")\n",
        "\n",
        "  #El modelo 'construye múltiples árboles de decisión' (según n_estimators).\n",
        "  #Cada árbol se entrena sobre una 'muestra aleatoria' del conjunto de entrenamiento.\n",
        "  #Se 'almacenan los patrones' para que luego pueda predecir sobre nuevos datos.\n",
        "  #Este paso es fundamental: el modelo aún no ha hecho predicciones ni evaluaciones, solo ha aprendido."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmC0CH7OBxpD",
        "outputId": "60617d1a-44e0-452e-96db-16049fc73962"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entrenamiento completado. El modelo ya está ajustado a los datos.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nueva sección"
      ],
      "metadata": {
        "id": "MxbJpmXRCQCU"
      }
    }
  ]
}